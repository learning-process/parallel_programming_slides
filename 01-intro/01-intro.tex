\documentclass{beamer}

% Theme choice
\usetheme{Madrid}

% Optional packages
\usepackage{graphicx} % For including images
\usepackage{amsmath}  % For math symbols and formulas
\usepackage{hyperref} % For hyperlinks
\usepackage{listings}
\usepackage{xcolor}
\usepackage[T1]{fontenc}

\lstdefinestyle{CStyle}{
  language=C,                    % Set the language to C
  basicstyle=\ttfamily\footnotesize\linespread{0.9}\tiny, % Set font style and size
  keywordstyle=\color{blue},      % Color of keywords
  commentstyle=\color{gray},      % Color of comments
  stringstyle=\color{red},        % Color of strings
  showstringspaces=false,         % Do not mark spaces in strings
  breaklines=true,                % Enable line breaks at appropriate places
  breakatwhitespace=false,        % Break lines at any character, not just whitespace
  numbers=left,                   % Show line numbers on the left
  numberstyle=\tiny\color{gray},  % Style for line numbers
  tabsize=4,                      % Set tab width
  keepspaces=true,                % Keep indentation spaces
  frame=single,                   % Add a border around the code
  aboveskip=0pt,                  % Reduce space above the code block
  belowskip=0pt,                   % Reduce space below the code block
  xleftmargin=7.5pt,                      % Add left padding (approx. 2.8mm or 10px)
  xrightmargin=15pt,                      % Add left padding (approx. 2.8mm or 10px)
}

% Title, author, date, and institute (optional)
\title[Parallel Programming. Introduction]{Parallel Programming course. Introduction}
\author{Obolenskiy Arseniy, Nesterov Alexander}
\institute{Nizhny Novgorod State University}

\date{\today} % or \date{Month Day, Year}

% Redefine the footline to display both the short title and the university name
\setbeamertemplate{footline}{
  \leavevmode%
  \hbox{%
    \begin{beamercolorbox}[wd=.45\paperwidth,ht=2.5ex,dp=1ex,leftskip=1em,center]{author in head/foot}%
        \usebeamerfont{author in head/foot}\insertshortinstitute % Displays the university name
    \end{beamercolorbox}%
    \begin{beamercolorbox}[wd=.45\paperwidth,ht=2.5ex,dp=1ex,leftskip=1em,center]{author in head/foot}%
      \usebeamerfont{author in head/foot}\insertshorttitle % Displays the short title
    \end{beamercolorbox}%
    \begin{beamercolorbox}[wd=.1\paperwidth,ht=2.5ex,dp=1ex,rightskip=1em,center]{author in head/foot}%
      \usebeamerfont{author in head/foot}\insertframenumber{} / \inserttotalframenumber
    \end{beamercolorbox}}%
  \vskip0pt%
}

\begin{document}

% Title slide
\begin{frame}
    \titlepage
\end{frame}

% Table of Contents (optional)
\begin{frame}{Contents}
    \tableofcontents
\end{frame}

% Section
\section{Introduction to MPI}

\begin{frame}[fragile]{What is MPI?}
  MPI (Message Passing Interface) is a standardized and portable message-passing system, designed to function on a variety of parallel computing architectures.

  Primarily used in high-performance computing (HPC) to allow different processes to communicate with each other in a distributed memory environment.
\end{frame}

\begin{frame}[fragile]{MPI: library vs standard}
  \begin{table}[h!]
    \begin{tabular}{| p{2.1cm} | p{4.2 cm} | p{4.2 cm} |}
      \hline
      \textbf{Aspect} & \textbf{MPI Standard} & \textbf{MPI Library} \\
      \hline
      \textbf{Definition} & A formal set of specifications & A concrete software implementation \\
      \hline
      \textbf{Purpose} & Defines the behavior of message-passing systems & Provides a runnable implementation of the standard \\
      \hline
      \textbf{Portability} & Platform-agnostic guidelines & Implementations may be platform-specific \\
      \hline
      \textbf{Performance} & No direct impact on performance & Optimized for different platforms and hardware \\
      \hline
      \textbf{Examples} & MPI-1, MPI-2, MPI-3, MPI-4 (specifications) & MPICH, Open MPI, MS MPI (Microsoft MPI), Intel MPI \\
      \hline
    \end{tabular}
    \caption{Key Differences Between MPI Standard and MPI Library}
  \end{table}
\end{frame}

\section{"Hello, World" in MPI}

% "Hello, World" in MPI
\begin{frame}[fragile]{"Hello, World" in MPI}

  \lstset{style=CStyle, caption=Basic application written using MPI}
  \begin{lstlisting}
#include <mpi.h>

#include <iostream>

int main(int argc, char** argv) {
  MPI_Init(&argc, &argv);

  int world_size;
  MPI_Comm_size(MPI_COMM_WORLD, &world_size);

  int world_rank;
  MPI_Comm_rank(MPI_COMM_WORLD, &world_rank);

  char processor_name[MPI_MAX_PROCESSOR_NAME];
  int len_chars;
  MPI_Get_processor_name(processor_name, &len_chars);

  MPI_Barrier(MPI_COMM_WORLD);
  std::cout << "Processor = " << processor_name << std::endl;
  std::cout << "Rank = " << world_rank << std::endl;
  std::cout << "Number of processors = " << world_size << std::endl;

  MPI_Finalize();
  return 0;
}
  \end{lstlisting}

\end{frame}

\begin{frame}[fragile]{Compiling MPI application}
  Linux: \\
  \texttt{mpicc -o hello\_mpi hello\_mpi.c}

  Windows: \\
  \texttt{cl /I"C:}\texttt{\textbackslash}\texttt{Program Files (x86)}\texttt{\textbackslash}\texttt{Microsoft SDKs}\texttt{\textbackslash}\texttt{MPI}\texttt{\textbackslash}\texttt{Include" hello\_mpi.c /link /LIBPATH:"C:}\texttt{\textbackslash}\texttt{Program Files (x86)}\texttt{\textbackslash}\texttt{Microsoft SDKs}\texttt{\textbackslash}\texttt{MPI}\texttt{\textbackslash}\texttt{Lib}\texttt{\textbackslash}\texttt{x64" msmpi.lib}

\end{frame}

\begin{frame}[fragile]{Running MPI application}
  Important! If you run application directly (\texttt{./hello\_mpi}) you will not get expected result!

  Linux: \\
  \texttt{mpirun -n 4 ./hello\_mpi}

  Windows: \\
  \texttt{mpiexec -n 4 hello\_mpi.exe}
\end{frame}

\section{Brief API calls overview}

\begin{frame}[fragile]{MPI initialization: \texttt{MPI\_Init()}}
  \texttt{int MPI\_Init(int *argc, char ***argv)}

  It initializes the MPI environment and must be called before any other MPI function.

  \lstset{style=CStyle, caption=Basic application written using MPI}
  \begin{lstlisting}
#include <mpi.h>
#include <stdio.h>

int main(int argc, char** argv) {
    // Initialize the MPI environment
    MPI_Init(&argc, &argv);

    ...

    return 0;
}
  \end{lstlisting}

\end{frame}

\section{MPI data distribution}

\begin{frame}[fragile]{MPI data distribution example}
  \lstset{style=CStyle, caption=MPI data distribution example}
  \begin{lstlisting}
    #include <mpi.h>
    #include <stdio.h>
    int main(int argc, char** argv) {
        // Initialize the MPI environment
        MPI_Init(&argc, &argv);
    
        // Get the number of processes
        int world_size;
        MPI_Comm_size(MPI_COMM_WORLD, &world_size);
    
        // Get the rank of the process
        int world_rank;
        MPI_Comm_rank(MPI_COMM_WORLD, &world_rank);
    
        // Define message
        int number = 0;
        if (world_rank == 0) {
            // If we are rank 0, set number to -1 and send it to process 1
            number = -1;
            MPI_Send(&number, 1, MPI_INT, 1, 0, MPI_COMM_WORLD);
            printf("Process 0 sent number %d to process 1\n", number);
        } else if (world_rank == 1) {
            // If we are rank 1, receive the number from process 0
            MPI_Recv(&number, 1, MPI_INT, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);
            printf("Process 1 received number %d from process 0\n", number);
        }
    
        // Finalize the MPI environment
        MPI_Finalize();
        return 0;
    }
  \end{lstlisting}

\end{frame}

\begin{frame}[fragile]{Problems in multiprocessing environment}
  There are some typical errors that may occur in multiprocessing environment.
  Case when there are variables allocated on all processes in quite common.
  \lstset{style=CStyle, caption=Common variables usage example}
  \begin{lstlisting}
    ...
    int main(int argc, char** argv) {
        ...
        // Pay attention to "number" variable
        int number; // NOTE: in this case data will be created on each process
        // If you leave this data uninitialized it may lead to an undefined behavior
        // on specific processes
        if (world_rank == 0) {
            // If we are rank 0, "number" variable will be initialized with -1.
            // OK here
            number = -1;
            MPI_Send(&number, 1, MPI_INT, 1, 0, MPI_COMM_WORLD);
            printf("Process 0 sent number %d to process 1\n", number);
        } else if (world_rank == 1) {
            // If we are rank 1, receive the number from process 0
            // OK here
            MPI_Recv(&number, 1, MPI_INT, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);
            printf("Process 1 received number %d from process 0\n", number);
        } else {
          // WARNING: If we are rank 2 and more, there is uninitialized "number" variable!
          // Potential mistake
        }
        ...
    }
  \end{lstlisting}
\end{frame}

\begin{frame}[fragile]{Problems in multiprocessing environment solution?}
  Example on previous slide may lead to an undefined behavior which is not obvious.

  \begin{itemize}
    \item In case of number of processes <= 2 there is no issue.
    \item In case of number of processes > 2 there is potential gap if we use \texttt{number} variable afterwards.
  \end{itemize}

  How to avoid memory issues?
  \begin{itemize}
    \item Do not initialize \texttt{number} variable outside \texttt{if} (create \texttt{number} inside \texttt{if} scope)
    \item Initialize \texttt{number} variable (e.g. \texttt{int number = 0;})
  \end{itemize}

  Important! This is the only one simple case of potential error in multiprocessing environment.
  Pay attention to the safety because debugging in multiprocessing environment is more challenging that in single process environment.
\end{frame}

\begin{frame}[fragile]{\texttt{MPI\_Send()}}
  \texttt{int MPI\_Send(const void *buf, int count, MPI\_Datatype datatype, int dest, int tag, MPI\_Comm comm)}

  Parameters:

  \begin{itemize}
    \item buf: The starting address of the data buffer to be sent.
    \item count: The number of elements in the buffer.
    \item datatype: The type of data being sent (e.g., \texttt{MPI\_INT}, \texttt{MPI\_FLOAT}).
    \item dest: The rank (ID) of the destination process.
    \item tag: A user-defined message identifier to differentiate messages.
    \item comm: The communicator that defines the group of processes within which the message is being sent (e.g., \texttt{MPI\_COMM\_WORLD}).
  \end{itemize}

  const void *buf, int count, MPI\_Datatype datatype - data array description
\end{frame}

\begin{frame}[fragile]{\texttt{MPI\_Recv()}}
  \texttt{int MPI\_Recv(void *buf, int count, MPI\_Datatype datatype, int source, int tag, MPI\_Comm comm, MPI\_Status *status)}

  Parameters:

  \begin{itemize}
    \item buf: The starting address of the buffer where the received data will be stored.
    \item count: The maximum number of elements that the buffer can hold.
    \item datatype: The type of data being received (e.g., \texttt{MPI\_INT}, \texttt{MPI\_FLOAT}).
    \item source: The rank of the sending process. Use \texttt{MPI\_ANY\_SOURCE} to receive from any process.
    \item tag: The message identifier (tag). Use \texttt{MPI\_ANY\_TAG} to receive any message regardless of the tag.
    \item comm: The communicator for the group of processes within which the message is being received (e.g., \texttt{MPI\_COMM\_WORLD}).
    \item status: A structure that contains information about the received message, such as the actual source and tag.
  \end{itemize}
\end{frame}

\begin{frame}[fragile]{MPI Communicators}
  MPI Communicator: A communicator in MPI defines a communication context, a group of processes that can send and receive messages from one another. The processes within a communicator are assigned unique ranks, which are integers that identify each process.

  Ranks: Every process within a communicator has a rank, starting from 0. The rank helps to uniquely identify a process within the communicator.

  Groups: A communicator has an associated group of processes. A group is an ordered set of processes, which MPI uses to determine communication partners.
\end{frame}

\begin{frame}[fragile]{\texttt{MPI\_COMM\_WORLD}}
  \texttt{MPI\_COMM\_WORLD}: The \texttt{MPI\_COMM\_WORLD} is the default communicator created when an MPI program starts. It includes all the processes that are initiated by the MPI runtime.
  \begin{itemize}
    \item Every process in the MPI application automatically becomes a part of \texttt{MPI\_COMM\_WORLD}, and this communicator is used for most communication operations in simple MPI programs.
    \item All the processes in the program are assigned a rank in \texttt{MPI\_COMM\_WORLD}, starting from 0 to the number of processes minus one.
    \item \texttt{MPI\_COMM\_WORLD} allows processes to exchange messages, perform collective operations (e.g. broadcasting, reducing, scattering, etc.), and more.
  \end{itemize}
\end{frame}

\begin{frame}[fragile]{Performance measurement in MPI: \texttt{MPI\_Wtime()}}
  \texttt{double MPI\_Wtime(void)}

  \begin{itemize}
    \item \texttt{MPI\_Wtime()} is a function provided by the MPI standard to measure the wall-clock time (in seconds) since some arbitrary point in the past.
    \item This function is often used for performance analysis in parallel programs to measure the execution time of sections of code.
    \item It returns a double precision floating-point number representing the current time. The returned time is in seconds.
    \item \texttt{MPI\_Wtime()} is local to the process and does not guarantee synchronization between processes, meaning each process may have a different starting time reference.
  \end{itemize}

  Usage example:
  \lstset{style=CStyle}
  \begin{lstlisting}
double start = MPI_Wtime();
// Code to time
double end = MPI_Wtime();
double elapsed = end - start;
  \end{lstlisting}

  Documentation reference: \texttt{\href{https://www.mpich.org/static/docs/v3.2/www3/MPI_Wtime.html}{https://www.mpich.org/static/docs/v3.2/www3/MPI\_Wtime.html}}
\end{frame}


% Thank You Slide
\begin{frame}
    \centering
    \Huge{Thank You!}
\end{frame}

% References slide
\begin{frame}{References}
  \begin{enumerate}
    \item MPI Standard \href{https://www.mpi-forum.org/docs/}{https://www.mpi-forum.org/docs/}
    \item MPICH guides: \href{https://www.mpich.org/documentation/guides/}{https://www.mpich.org/documentation/guides/}
    \item Microsoft MPI: \href{https://learn.microsoft.com/en-us/message-passing-interface/microsoft-mpi}{https://learn.microsoft.com/en-us/message-passing-interface/microsoft-mpi}
    \item OpenMPI docs: \href{https://www.open-mpi.org/doc/}{https://www.open-mpi.org/doc/}
  \end{enumerate}
\end{frame}

\end{document}
